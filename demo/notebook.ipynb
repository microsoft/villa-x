{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a79e6f06",
   "metadata": {},
   "source": [
    "### Latent Action Model Demo\n",
    "\n",
    "1. Clone the repository and install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585566d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/microsoft/villa-x.git\n",
    "!curl -LsSf https://astral.sh/uv/install.sh | sh\n",
    "!sudo apt-get install -y build-essential zlib1g-dev libffi-dev libssl-dev libbz2-dev libreadline-dev libsqlite3-dev liblzma-dev libncurses-dev tk-dev python3-dev ffmpeg -y\n",
    "!cd villa-x && uv sync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a49505",
   "metadata": {},
   "source": [
    "2. Download villa-X checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6367efc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://huggingface.co/microsoft/villa-x villax_checkpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae2d01a",
   "metadata": {},
   "source": [
    "3. Load the latent action model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13159215",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lam import IgorModel\n",
    "\n",
    "lam = IgorModel.from_pretrained(\"villax_checkpoint\").cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba09704",
   "metadata": {},
   "source": [
    "4. Extract latent actions from a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a3e8bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def read_video(fp: str):\n",
    "    from torchvision.io import read_video\n",
    "\n",
    "    video, *_ = read_video(fp, pts_unit=\"sec\")\n",
    "    return video.permute(0, 3, 1, 2)\n",
    "\n",
    "\n",
    "def read_image(fp: str):\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    from PIL import Image\n",
    "\n",
    "    image = Image.open(fp).convert(\"RGB\")\n",
    "\n",
    "    return torch.tensor(np.array(image)).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "def save_video(frames, output_path, fps=30):\n",
    "    from torchvision.io import write_video\n",
    "\n",
    "    write_video(output_path, frames, fps=fps)\n",
    "\n",
    "\n",
    "video = read_video(\"example_01.mp4\").cuda()  # Load your video here\n",
    "latent_action = lam.idm(video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a97c144",
   "metadata": {},
   "source": [
    "4. Use image FDM to generate reconstructed frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1000bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = [video[0]]\n",
    "for i in range(0, len(latent_action[0])):\n",
    "    reconstructed_frame = lam.apply_latent_action(video[i], latent_action[0][i])\n",
    "    recon.append(reconstructed_frame)\n",
    "\n",
    "save_video(\n",
    "    torch.cat([video, torch.stack(recon)], dim=3).permute(0, 2, 3, 1),\n",
    "    \"recon_video.mp4\",\n",
    "    fps=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3eca47",
   "metadata": {},
   "source": [
    "5. Iteratively generate future frames from latent actions using image FDM. (To be replaced with world model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16b835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_frame = read_image(\"example_target_01.png\").cuda()  # Load your target frame here\n",
    "\n",
    "frames = [cur_frame]\n",
    "for la in latent_action[0]:\n",
    "    cur_frame = lam.apply_latent_action(cur_frame, la)\n",
    "    frames.append(cur_frame)\n",
    "\n",
    "frames = torch.cat([video, torch.stack(frames)], dim=3).permute(0, 2, 3, 1)\n",
    "save_video(frames, \"iterative_video.mp4\", fps=5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "villax",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
